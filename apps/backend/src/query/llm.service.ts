import { Injectable, Logger } from '@nestjs/common';
import axios, { AxiosError } from 'axios';
import { ModelConfigService } from '../common/model-config.service';

/**
 * LLM æœå‹™
 * è™•ç†èˆ‡ LLM çš„äº¤äº’
 */
@Injectable()
export class LlmService {
  private readonly logger = new Logger(LlmService.name);

  // é è¨­çš„ System Prompt
  private readonly DEFAULT_SYSTEM_PROMPT = `æ ¹æ“šä½¿ç”¨è€…å•é¡Œçš„èªæ„åˆ¤æ–·ï¼Œå¾çŸ¥è­˜åº«å…§å®¹æŒ‘å‡ºå¯èƒ½ç¬¦åˆçš„Q&Aé …ç›®ã€‚

**ç¯©é¸åŸå‰‡ï¼š**
- å¾ questionã€answer å’Œ synonymï¼ˆåŒç¾©è©ï¼‰çš„å…§å®¹ä¾†åˆ¤æ–·æ˜¯å¦å¯èƒ½ç‚ºä½¿ç”¨è€…è¦æ‰¾çš„
- **synonym æ¬„ä½éå¸¸é‡è¦**ï¼šå¦‚æœä½¿ç”¨è€…å•é¡Œèˆ‡ synonym æ¬„ä½ä¸­çš„è©å½™ç›¸é—œï¼Œå³ä½¿ question ä¸å®Œå…¨åŒ¹é…ï¼Œä¹Ÿæ‡‰è©²è¦–ç‚ºç›¸é—œ
- ä½¿ç”¨è€…å•é¡Œå¯èƒ½æœ‰å¤šç¨®è¡¨é”æ–¹å¼ï¼Œéœ€è¦æ ¹æ“šå•é¡Œçš„èªæ„ä¾†åˆ¤æ–·
- ä¸ç›¸å¹²çš„ Q&A éœ€è¦æ’é™¤
- å¯èƒ½å¤šå€‹Q&Aç¬¦åˆï¼Œæœ€å¤šè¿”å›5å€‹

**å›ç­”æ–¹å¼ï¼š**
- **å¿…é ˆä»¥ **JSON æ ¼å¼**è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
\`\`\`json
{
  "has_results": true,
  "intro": "ä»¥ä¸‹å¯èƒ½æ˜¯æ‚¨éœ€è¦çš„...",
  "results": [
    {
      "faq_id": "faq_123",
      "question": "å®Œæ•´å•é¡Œæ–‡æœ¬"
    },
    {
      "faq_id": "faq_456",
      "question": "å¦ä¸€å€‹å•é¡Œ"
    }
  ]
}
\`\`\`

- **å¦‚æœæä¾›çš„å…§å®¹ç‚ºç©ºï¼ˆcontext ç‚ºç©ºé™£åˆ— []ï¼‰**ï¼š**å¿…é ˆ**è¿”å›ä»¥ä¸‹ JSONï¼š
\`\`\`json
{
  "has_results": false,
  "intro": "æŠ±æ­‰ï¼Œæ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„è³‡è¨Šã€‚è«‹å˜—è©¦æ›å€‹æ–¹å¼æå•ã€‚",
  "results": []
}
\`\`\`

**é‡è¦è¦æ±‚ï¼š**
1. **å¿…é ˆ**è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼
2. **ä¸è¦**æ·»åŠ ä»»ä½• JSON ä¹‹å¤–çš„æ–‡å­—æˆ–èªªæ˜

**æ³¨æ„ï¼š**
- ä½ å°‡æ”¶åˆ° JSON æ ¼å¼çš„çŸ¥è­˜åº«å…§å®¹ï¼Œæ ¼å¼ç‚ºï¼š\`{"context": [{"faq_id": "...", "question": "...", "answer": "...", "synonym": "...", "score": 0.xx}]}\`
- **synonym æ¬„ä½åŒ…å«åŒç¾©è©**ï¼šå¦‚æœä½¿ç”¨è€…å•é¡Œèˆ‡ synonym ä¸­çš„è©å½™ç›¸é—œï¼Œå³ä½¿ question ä¸å®Œå…¨åŒ¹é…ï¼Œä¹Ÿæ‡‰è©²è¦–ç‚ºç›¸é—œä¸¦è¿”å›
- å¦‚æœ \`context\` ç‚ºç©ºé™£åˆ— \`[]\`ï¼Œè¡¨ç¤ºæ²’æœ‰æ‰¾åˆ°ç›¸é—œè³‡æ–™ï¼Œ**å¿…é ˆ**è¿”å› \`has_results: false\`
- å¦‚æœ \`context\` æœ‰è³‡æ–™ï¼Œè«‹å¾ä¸­é¸æ“‡æœ€ç›¸é—œçš„ FAQï¼Œä¸¦è¿”å›å°æ‡‰çš„ \`faq_id\` å’Œ \`question\`
`;

  constructor(private readonly modelConfigService: ModelConfigService) {}

  /**
   * èª¿ç”¨ LLM API
   * å‘¼å« OpenAI LLM API
   * 
   * @param messages å°è©±æ¶ˆæ¯åˆ—è¡¨
   * @param apiUrl API åŸºç¤ URL
   * @param apiKey API Key
   * @param modelName æ¨¡å‹åç¨±
   * @param temperature æº«åº¦åƒæ•¸
   * @param maxTokens æœ€å¤§ token æ•¸
   * @param provider Provider é¡å‹ ('openai' æˆ– 'azure-openai')
   * @param apiVersion API ç‰ˆæœ¬ï¼ˆåƒ… Azure OpenAI éœ€è¦ï¼‰
   * @returns LLM å›æ‡‰
   */
  async callLlmOpenai(
    messages: Array<{ role: string; content: string }>,
    apiUrl: string,
    apiKey: string,
    modelName: string,
    temperature: number,
    maxTokens: number,
    provider: string = 'openai',
    apiVersion?: string,
  ): Promise<{
    content: string;
    model: string;
    provider: string;
    usage: any;
  }> {
    // é©—è­‰å¿…è¦é…ç½®
    if (!apiUrl) {
      throw new Error('æœªè¨­ç½® API URLï¼Œç„¡æ³•èª¿ç”¨ LLM');
    }
    if (!apiKey) {
      throw new Error('æœªè¨­ç½® API Keyï¼Œç„¡æ³•èª¿ç”¨ LLM');
    }
    if (!modelName) {
      throw new Error('æœªè¨­ç½® Model Nameï¼Œç„¡æ³•èª¿ç”¨ LLM');
    }

    // ç§»é™¤ API URL çµå°¾çš„æ–œç·š
    apiUrl = apiUrl.replace(/\/$/, '');

    // æ§‹å»º endpoint URL
    let endpoint: string;
    if (provider === 'azure-openai') {
      // Azure OpenAI URL æ ¼å¼
      if (!apiVersion) {
        apiVersion = '2024-02-15-preview'; // é è¨­ç‰ˆæœ¬
      }
      endpoint = `${apiUrl}/openai/deployments/${modelName}/chat/completions?api-version=${apiVersion}`;
    } else {
      // æ¨™æº– OpenAI URL æ ¼å¼
      endpoint = `${apiUrl}/chat/completions`;
    }

    // æ ¹æ“š provider é¸æ“‡èªè­‰æ–¹å¼
    const headers: any = {
      'Content-Type': 'application/json',
    };

    if (provider === 'azure-openai') {
      // Azure OpenAI ä½¿ç”¨ 'api-key' header
      headers['api-key'] = apiKey;
    } else {
      // æ¨™æº– OpenAI ä½¿ç”¨ 'Authorization: Bearer' header
      headers['Authorization'] = `Bearer ${apiKey}`;
    }

    // æº–å‚™è«‹æ±‚é«”
    const payload = {
      model: modelName,
      messages,
      temperature,
      max_tokens: maxTokens,
    };

    try {
      const response = await axios.post(endpoint, payload, {
        headers,
        timeout: 60000, // 60 ç§’è¶…æ™‚
      });

      const data = response.data;
      const choices = data.choices || [];

      if (choices.length > 0) {
        const message = choices[0].message || {};
        const text = message.content || '';

        return {
          content: text,
          model: data.model || modelName,
          provider,
          usage: data.usage || {},
        };
      } else {
        throw new Error('API å›æ‡‰æ ¼å¼éŒ¯èª¤: æ‰¾ä¸åˆ°é¸æ“‡çµæœ');
      }
    } catch (error: any) {
      if (axios.isAxiosError(error)) {
        const axiosError = error as AxiosError;
        let errorDetail = 'æœªçŸ¥éŒ¯èª¤';

        if (axiosError.response) {
          // HTTP éŒ¯èª¤
          const responseData: any = axiosError.response.data || {};
          errorDetail =
            responseData.error?.message || JSON.stringify(responseData);

          throw new Error(
            `LLM API å¤±æ•— (${axiosError.response.status}): ${errorDetail}`,
          );
        } else if (axiosError.request) {
          // è«‹æ±‚ç™¼é€å¤±æ•—
          throw new Error(`ç„¡æ³•é€£æ¥åˆ° API ä¼ºæœå™¨: ${axiosError.message}`);
        }
      }

      throw new Error(`LLM èª¿ç”¨å¤±æ•—: ${error.message}`);
    }
  }

  /**
   * ç™¼é€ FAQ æœå°‹çµæœçµ¦ LLM ä¸¦ç²å–å›æ‡‰
   * ç™¼é€ FAQ åˆ° LLM
   * 
   * @param query ç”¨æˆ¶å•é¡Œ
   * @param searchResults Elasticsearch æœå°‹çµæœåˆ—è¡¨
   * @returns LLM å›æ‡‰
   */
  async sendFaqToLlm(
    query: string,
    searchResults: Array<{
      faq_id: string;
      question: string;
      answer: string;
      synonym?: string;
      score: number;
    }>,
  ): Promise<{
    content: string;
    model: string;
    provider: string;
    usage: any;
  }> {
    // é©—è­‰è¼¸å…¥
    if (!query || !query.trim()) {
      throw new Error('æŸ¥è©¢æ–‡æœ¬ä¸èƒ½ç‚ºç©º');
    }

    query = query.trim();

    // ========== æ­¥é©Ÿ 1: è™•ç†æœå°‹çµæœ ==========
    // æŒ‰åˆ†æ•¸é™åºæ’åº
    const sortedResults = [...searchResults].sort((a, b) => b.score - a.score);

    // ========== æ­¥é©Ÿ 2: å¾ç’°å¢ƒè®Šæ•¸ç²å– LLM é…ç½® ==========
    const llmModel = this.modelConfigService.getCurrentLLMModel();

    if (!llmModel) {
      throw new Error('è«‹è¨­ç½®ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY');
    }

    const apiUrl = llmModel.apiUrl || '';
    const apiKey = llmModel.apiKey || '';
    const modelName = llmModel.modelName || '';
    const temperature = llmModel.temperature || 0.7;
    const maxTokens = llmModel.maxTokens || 1000;
    const provider = llmModel.provider || 'openai';
    const apiVersion = llmModel.apiVersion;

    this.logger.log(
      `[Send FAQ to LLM] ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ä¸­çš„ LLM é…ç½®: provider=${provider}, model=${modelName}, temperature=${temperature}, max_tokens=${maxTokens}`,
    );

    // ========== æ­¥é©Ÿ 3: æ§‹å»ºæ¶ˆæ¯æ­·å² ==========
    const messageHistory: Array<{ role: string; content: string }> = [];

    // æ·»åŠ  system prompt
    messageHistory.push({
      role: 'system',
      content: this.DEFAULT_SYSTEM_PROMPT,
    });

    // æ§‹å»ºåŒ…å«æœå°‹çµæœçš„ç”¨æˆ¶æ¶ˆæ¯
    const contextData = {
      context: sortedResults.map((result) => ({
        faq_id: result.faq_id,
        question: result.question,
        answer: result.answer,
        synonym: result.synonym || '', // åŠ å…¥ synonym æ¬„ä½
        score: Math.round(result.score * 10000) / 10000, // ä¿ç•™ 4 ä½å°æ•¸
      })),
    };

    // æ ¼å¼åŒ–ç‚º JSON å­—ä¸²ä¸¦æ§‹å»ºç”¨æˆ¶æ¶ˆæ¯
    const contextJson = JSON.stringify(contextData, null, 2);
    const userMessageContent = `ä½¿ç”¨è€…å•é¡Œï¼š${query}\n\nã€ç›¸é—œçŸ¥è­˜åº«å…§å®¹ï¼ˆJSON æ ¼å¼ï¼‰ã€‘\n\n${contextJson}\n`;

    // æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯
    messageHistory.push({
      role: 'user',
      content: userMessageContent,
    });

    // ========== æ­¥é©Ÿ 4: èª¿ç”¨ LLM ==========
    try {
      const result = await this.callLlmOpenai(
        messageHistory,
        apiUrl,
        apiKey,
        modelName,
        temperature,
        maxTokens,
        provider,
        apiVersion,
      );

      this.logger.log(`[Send FAQ to LLM] âœ… LLM èª¿ç”¨æˆåŠŸ`);
      this.logger.log(
        `[Send FAQ to LLM] ğŸ“Š æœå°‹çµæœæ•¸é‡: ${sortedResults.length}`,
      );
      this.logger.log(`[Send FAQ to LLM] ğŸ“ ç”¨æˆ¶å•é¡Œ: ${query}`);
      if (sortedResults.length > 0) {
        this.logger.log(
          `[Send FAQ to LLM] ğŸ“Š æœ€é«˜åˆ†æ•¸: ${sortedResults[0].score}`,
        );
      }

      return result;
    } catch (error: any) {
      this.logger.error(`[Send FAQ to LLM] âŒ LLM èª¿ç”¨å¤±æ•—: ${error.message}`);
      throw error;
    }
  }

  /**
   * è§£æ LLM JSON å›æ‡‰ä¸¦è½‰æ›ç‚º QABlock
   * å°‡ LLM å›æ‡‰è½‰æ›ç‚º QABlock
   * 
   * æ³¨æ„ï¼šæœƒå¾è³‡æ–™åº«æŸ¥è©¢å®Œæ•´çš„ FAQ æ•¸æ“šï¼ˆåŒ…å« layout å’Œ imagesï¼‰
   * 
   * @param llmResponse LLM å›æ‡‰
   * @param faqMap FAQ å­—å…¸ (faq_id -> FAQ) - å¯é¸ï¼Œå¦‚æœä¸æä¾›å‰‡å¾è³‡æ–™åº«æŸ¥è©¢
   * @param prismaService Prisma Service å¯¦ä¾‹ï¼ˆç”¨æ–¼æŸ¥è©¢è³‡æ–™åº«ï¼‰
   * @returns QABlock åˆ—è¡¨å’Œ intro
   */
  async parseLlmResponse(
    llmResponse: {
      content: string;
      model: string;
      provider: string;
      usage: any;
    },
    faqMap?: Map<
      string,
      {
        faq_id: string;
        question: string;
        answer: string;
      }
    >,
    prismaService?: any,
  ): Promise<{
    intro: string | null;
    qa_blocks: Array<{
      faq_id: string;
      question: string;
      answer: string;
      layout?: string;
      images?: string;
    }>;
  }> {
    const rawContent = llmResponse.content;

    try {
      // ========== æ­¥é©Ÿ 1: è§£æ JSON å›æ‡‰ ==========
      // 1.1 æå– JSON å…§å®¹ï¼ˆå»é™¤å¯èƒ½çš„ markdown ä»£ç¢¼å¡Šï¼‰
      let jsonContent = rawContent.trim();

      // å¦‚æœåŒ…å« ```json ... ```ï¼Œæå–ä¸­é–“çš„ JSON
      const jsonMatch = jsonContent.match(/```json\s*\n([\s\S]*?)\n```/);
      if (jsonMatch) {
        jsonContent = jsonMatch[1].trim();
      } else {
        // å˜—è©¦æå–ä»»ä½• ``` ... ``` ä»£ç¢¼å¡Š
        const codeBlockMatch = jsonContent.match(/```\s*\n?([\s\S]*?)\n?```/);
        if (codeBlockMatch) {
          jsonContent = codeBlockMatch[1].trim();
        }
      }

      // 1.2 è§£æ JSON
      const jsonData = JSON.parse(jsonContent);

      // ========== æ­¥é©Ÿ 2: æå–æ•¸æ“š ==========
      const hasResults = jsonData.has_results || false;
      const intro = jsonData.intro || null;
      const results = jsonData.results || [];

      if (!hasResults || results.length === 0) {
        // æ²’æœ‰æ‰¾åˆ°çµæœ
        return {
          intro: intro || 'æŠ±æ­‰ï¼Œæ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„è³‡è¨Šã€‚',
          qa_blocks: [],
        };
      }

      // ========== æ­¥é©Ÿ 3: è½‰æ›ç‚º QABlock ==========
      const qaBlocks: Array<{
        faq_id: string;
        question: string;
        answer: string;
        layout?: string;
        images?: string;
      }> = [];

      for (const result of results) {
        const faqId = result.faq_id || '';
        const llmQuestion = result.question || '';

        if (!faqId) {
          this.logger.warn(`[Parse LLM Response] è·³éç¼ºå°‘ faq_id çš„çµæœ`);
          continue;
        }

        // ========== å¾è³‡æ–™åº«æŸ¥è©¢å®Œæ•´çš„ FAQ æ•¸æ“šï¼ˆåŒ…å« layout å’Œ imagesï¼‰==========
        let dbQuestion: string | null = null;
        let dbAnswer: string | null = null;
        let layout: string | null = null;
        let images: string | null = null;

        try {
          if (prismaService) {
            // å¾è³‡æ–™åº«æŸ¥è©¢å®Œæ•´æ•¸æ“š
            const faqData = await prismaService.faq.findUnique({
              where: { id: faqId },
              select: {
                question: true,
                answer: true,
                layout: true,
                images: true,
              },
            });

            if (faqData) {
              dbQuestion = faqData.question;
              dbAnswer = faqData.answer;
              layout = faqData.layout || 'text';
              images = faqData.images;
              this.logger.debug(
                `[Parse LLM Response] FAQ ${faqId} - layout: ${layout}, images: ${images}`,
              );
            } else {
              this.logger.warn(
                `[Parse LLM Response] FAQ ${faqId} ä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ï¼Œè·³é`,
              );
              continue;
            }
          } else if (faqMap) {
            // Fallback: å¾ faqMap ç²å–ï¼ˆä¸åŒ…å« layout å’Œ imagesï¼‰
            const faq = faqMap.get(faqId);
            if (!faq) {
              this.logger.warn(
                `[Parse LLM Response] æ‰¾ä¸åˆ° FAQ: ${faqId}ï¼Œè·³é`,
              );
              continue;
            }
            dbQuestion = faq.question;
            dbAnswer = faq.answer;
            layout = 'text'; // é è¨­å¸ƒå±€
          } else {
            this.logger.warn(
              `[Parse LLM Response] ç„¡æ³•ç²å– FAQ ${faqId} çš„æ•¸æ“šï¼ˆç¼ºå°‘ prismaService å’Œ faqMapï¼‰ï¼Œè·³é`,
            );
            continue;
          }
        } catch (error: any) {
          this.logger.warn(
            `[Parse LLM Response] âš ï¸ æŸ¥è©¢ FAQ ${faqId} å¤±æ•—: ${error.message}ï¼Œè·³é`,
          );
          continue;
        }

        // ç¢ºä¿æœ‰ç­”æ¡ˆæ‰æ·»åŠ 
        if (!dbAnswer) {
          this.logger.warn(
            `[Parse LLM Response] FAQ ${faqId} çš„ answer ç‚ºç©ºï¼Œè·³é`,
          );
          continue;
        }

        // ä½¿ç”¨è³‡æ–™åº«ä¸­çš„å®Œæ•´æ•¸æ“š
        const finalQuestion = dbQuestion || llmQuestion;
        const finalAnswer = dbAnswer.replace(/\\n/g, '\n'); // å°‡æ›è¡Œç¬¦ \n è½‰æ›ç‚ºå¯¦éš›æ›è¡Œ

        const qaBlock: any = {
          faq_id: faqId,
          question: finalQuestion,
          answer: finalAnswer,
        };

        // æ·»åŠ å¯é¸æ¬„ä½
        if (layout) {
          qaBlock.layout = layout;
        }
        if (images) {
          qaBlock.images = images;
        }

        qaBlocks.push(qaBlock);
      }

      this.logger.debug(
        `[Parse LLM Response] è§£æå¾Œçš„ qa_blocks æ•¸é‡: ${qaBlocks.length}`,
      );

      return {
        intro,
        qa_blocks: qaBlocks,
      };
    } catch (error: any) {
      this.logger.error(
        `[Parse LLM Response] âŒ è§£æ JSON å¤±æ•—: ${error.message}`,
      );
      this.logger.debug(`[Parse LLM Response] åŸå§‹å…§å®¹: ${rawContent}`);

      // è§£æå¤±æ•—ï¼Œè¿”å›ç©ºçµæœ
      return {
        intro: 'æŠ±æ­‰ï¼Œè™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚',
        qa_blocks: [],
      };
    }
  }
}

